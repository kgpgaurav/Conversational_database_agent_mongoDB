{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade google-generativeai gradio pymongo nltk\n",
    "# %pip install google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ff711",
   "metadata": {},
   "source": [
    "## Your env file\n",
    "#### GEMINI_API_KEY= *************\n",
    "#### MONGODB_URI= mongodb+srv://test_user:my123@analytics.mongodb.net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27530b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION SETUP\n",
    "# =============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration class for API keys and database settings\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # MongoDB Atlas Configuration\n",
    "        self.MONGODB_URI = \"mongodb+srv://test_user:my123@analytics"\n",
    "        self.DATABASE_NAME = \"sample_analytics\"\n",
    "        self.COLLECTIONS = [\"accounts\", \"customers\", \"transactions\"]\n",
    "        \n",
    "        # Google Gemini Configuration\n",
    "        self.GEMINI_API_KEY = self.get_gemini_key()\n",
    "        self.MODEL_NAME = \"gemini-2.0-flash\"\n",
    "        self.MAX_OUTPUT_TOKENS = 10000\n",
    "        self.TEMPERATURE = 0.3\n",
    "        \n",
    "    def get_gemini_key(self):\n",
    "        \"\"\"Get Google Gemini API key from environment or user input\"\"\"\n",
    "        try:\n",
    "            # Try Google Colab secrets first\n",
    "            from google.colab import userdata\n",
    "            return userdata.get('GEMINI_API_KEY')\n",
    "        except:\n",
    "            # Fallback to environment variable or manual input\n",
    "            api_key = os.getenv('GEMINI_API_KEY')\n",
    "            if not api_key:\n",
    "                api_key = input(\"Please enter your Google Gemini API key: \")\n",
    "            return api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1690e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATABASE HANDLER\n",
    "# =============================================================================\n",
    "\n",
    "class DatabaseHandler:\n",
    "    \"\"\"Handles all MongoDB operations and schema discovery\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.client = None\n",
    "        self.db = None\n",
    "        self.schema_cache = {}\n",
    "        self.connect()\n",
    "        \n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection to MongoDB Atlas\"\"\"\n",
    "        try:\n",
    "            self.client = MongoClient(self.config.MONGODB_URI)\n",
    "            self.client.admin.command('ping')\n",
    "            self.db = self.client[self.config.DATABASE_NAME]\n",
    "            print(\"âœ… Successfully connected to MongoDB Atlas\")\n",
    "            self.discover_schema()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error connecting to MongoDB: {e}\")\n",
    "            raise ConnectionError(f\"Failed to connect to MongoDB: {e}\")\n",
    "    \n",
    "    def discover_schema(self):\n",
    "        \"\"\"Discover and cache database schema\"\"\"\n",
    "        print(\"ğŸ” Discovering database schema...\")\n",
    "        \n",
    "        for collection_name in self.config.COLLECTIONS:\n",
    "            try:\n",
    "                collection = self.db[collection_name]\n",
    "                sample_docs = list(collection.find().limit(10))\n",
    "                \n",
    "                if sample_docs:\n",
    "                    schema = self.extract_schema(sample_docs)\n",
    "                    self.schema_cache[collection_name] = schema\n",
    "                    print(f\"ğŸ“‹ Schema discovered for {collection_name}\")\n",
    "                else:\n",
    "                    print(f\"âš ï¸ No documents found in {collection_name}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error discovering schema for {collection_name}: {e}\")\n",
    "                self.schema_cache[collection_name] = {\"fields\": {}, \"sample_values\": {}}\n",
    "    \n",
    "    def extract_schema(self, documents: List[Dict]) -> Dict:\n",
    "        \"\"\"Extract schema information from sample documents\"\"\"\n",
    "        schema = {\"fields\": {}, \"sample_values\": {}}\n",
    "        \n",
    "        for doc in documents:\n",
    "            for key, value in doc.items():\n",
    "                if key not in schema[\"fields\"]:\n",
    "                    schema[\"fields\"][key] = type(value).__name__\n",
    "                    schema[\"sample_values\"][key] = str(value)[:100]\n",
    "                \n",
    "        return schema\n",
    "    \n",
    "    def execute_query(self, collection_name: str, query: Dict, operation: str = \"find\") -> List[Dict]:\n",
    "        \"\"\"Execute MongoDB query and return results\"\"\"\n",
    "        try:\n",
    "            collection = self.db[collection_name]\n",
    "            \n",
    "            if operation == \"find\":\n",
    "                results = list(collection.find(query).limit(20))\n",
    "            elif operation == \"count\":\n",
    "                results = [{\"count\": collection.count_documents(query)}]\n",
    "            elif operation == \"aggregate\":\n",
    "                results = list(collection.aggregate(query))\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported operation: {operation}\")\n",
    "                \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error executing query: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_collection_stats(self, collection_name: str) -> Dict:\n",
    "        \"\"\"Get basic statistics for a collection\"\"\"\n",
    "        try:\n",
    "            collection = self.db[collection_name]\n",
    "            stats = {\n",
    "                \"total_documents\": collection.count_documents({}),\n",
    "                \"sample_document\": collection.find_one(),\n",
    "                \"collection_name\": collection_name\n",
    "            }\n",
    "            return stats\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error getting stats for {collection_name}: {e}\")\n",
    "            return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a659dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP PROCESSOR WITH GOOGLE GEMINI\n",
    "# =============================================================================\n",
    "\n",
    "class NLPProcessor:\n",
    "    \"\"\"Handles natural language processing and query translation using Google Gemini\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.client = genai.Client(api_key=config.GEMINI_API_KEY)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and preprocess input text\"\"\"\n",
    "        text = text.lower().strip()\n",
    "        ttext = re.sub(r'[^\\w\\s\\>\\<\\=\\!\\$]', ' ', text)\n",
    "        return text\n",
    "    \n",
    "    def classify_query_type(self, query: str) -> str:\n",
    "        \"\"\"Classify the type of query\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        if any(word in query_lower for word in ['count', 'how many', 'number of']):\n",
    "            return 'count'\n",
    "        elif any(word in query_lower for word in ['show', 'list', 'display', 'find']):\n",
    "            return 'find'\n",
    "        elif any(word in query_lower for word in ['average', 'mean', 'sum', 'total']):\n",
    "            return 'aggregate'\n",
    "        elif any(word in query_lower for word in ['what is', 'define', 'explain']):\n",
    "            return 'definition'\n",
    "        else:\n",
    "            return 'find'\n",
    "    \n",
    "    def translate_to_mongodb(self, query: str, schema: Dict, query_type: str, context: str = \"\") -> Tuple[str, Dict, str]:\n",
    "        \"\"\"Translate natural language to MongoDB query using Google Gemini\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert in translating natural language to MongoDB queries.\n",
    "\n",
    "        Conversation context:\n",
    "        {context}\n",
    "\n",
    "        Current user query: {query}\n",
    "        Query Type: {query_type}\n",
    "        Available Collections: accounts, customers, transactions\n",
    "\n",
    "        Schema Information:\n",
    "        - accounts: {schema.get('accounts', {})}\n",
    "        - customers: {schema.get('customers', {})}\n",
    "        - transactions: {schema.get('transactions', {})}\n",
    "\n",
    "        Return response in this JSON format:\n",
    "        {{\n",
    "            \"collection\": \"collection_name\",\n",
    "            \"query\": {{}},\n",
    "            \"operation\": \"find|count|aggregate\",\n",
    "            \"explanation\": \"Brief explanation of the query\"\n",
    "        }}\n",
    "\n",
    "        Examples:\n",
    "        - \"Show me all accounts\" -> {{\"collection\": \"accounts\", \"query\": {{}}, \"operation\": \"find\"}}\n",
    "        - \"How many customers are there?\" -> {{\"collection\": \"customers\", \"query\": {{}}, \"operation\": \"count\"}}\n",
    "        - \"Find accounts with limit greater than 5000\" -> {{\"collection\": \"accounts\", \"query\": {{\"limit\": {{\"$gt\": 5000}}}}, \"operation\": \"find\"}}\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.config.MODEL_NAME,\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    max_output_tokens=self.config.MAX_OUTPUT_TOKENS,\n",
    "                    temperature=self.config.TEMPERATURE\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            response_text = response.text.strip()\n",
    "            \n",
    "            # Extract JSON from response\n",
    "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                query_json = json.loads(json_match.group())\n",
    "                return query_json['collection'], query_json['query'], query_json['operation']\n",
    "            else:\n",
    "                # Fallback to default\n",
    "                return 'accounts', {}, 'find'\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error translating query: {e}\")\n",
    "            return 'accounts', {}, 'find'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba60ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSATION MEMORY\n",
    "# =============================================================================\n",
    "\n",
    "class ConversationMemory:\n",
    "    \"\"\"Manages conversation history and context\"\"\"\n",
    "    \n",
    "    def __init__(self, max_history=10):\n",
    "        self.max_history = max_history\n",
    "        self.conversation_history = []\n",
    "        self.context = {}\n",
    "        \n",
    "    def add_interaction(self, user_query: str, response: str, query_info: Dict = None):\n",
    "        \"\"\"Add a new interaction to conversation history\"\"\"\n",
    "        interaction = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"user_query\": user_query,\n",
    "            \"response\": response,\n",
    "            \"query_info\": query_info or {}\n",
    "        }\n",
    "        \n",
    "        self.conversation_history.append(interaction)\n",
    "        \n",
    "        # Keep only recent interactions\n",
    "        if len(self.conversation_history) > self.max_history:\n",
    "            self.conversation_history = self.conversation_history[-self.max_history:]\n",
    "    \n",
    "    def is_follow_up_query(self, query: str) -> bool:\n",
    "        \"\"\"Detect if current query is a follow-up to previous conversation\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return False\n",
    "            \n",
    "        follow_up_indicators = [\n",
    "            'what about', 'how about', 'what else', 'tell me more',\n",
    "            'and', 'also', 'additionally', 'furthermore',\n",
    "            'they', 'them', 'it', 'those', 'these', 'that'\n",
    "        ]\n",
    "        \n",
    "        query_lower = query.lower()\n",
    "        return any(indicator in query_lower for indicator in follow_up_indicators)\n",
    "    \n",
    "    def get_context_for_query(self, query: str) -> str:\n",
    "        \"\"\"Get relevant context from conversation history\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"\"\n",
    "            \n",
    "        recent_interactions = self.conversation_history[-3:]  # Last 3 interactions\n",
    "        \n",
    "        context = \"Recent conversation context:\\n\"\n",
    "        for interaction in recent_interactions:\n",
    "            context += f\"User: {interaction['user_query']}\\n\"\n",
    "            context += f\"Assistant: {interaction['response'][:200]}...\\n\\n\"\n",
    "            \n",
    "        return context\n",
    "    \n",
    "    def get_conversation_summary(self) -> str:\n",
    "        \"\"\"Get a summary of the entire conversation\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"No conversation history.\"\n",
    "            \n",
    "        summary = f\"Conversation has {len(self.conversation_history)} interactions:\\n\"\n",
    "        for i, interaction in enumerate(self.conversation_history, 1):\n",
    "            summary += f\"{i}. {interaction['user_query'][:50]}...\\n\"\n",
    "            \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a70bc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPONSE GENERATOR WITH GOOGLE GEMINI\n",
    "# =============================================================================\n",
    "\n",
    "class ResponseGenerator:\n",
    "    \"\"\"Generates human-like responses based on query results using Google Gemini\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.client = genai.Client(api_key=config.GEMINI_API_KEY)\n",
    "    \n",
    "    def generate_response(self, query: str, results: List[Dict], \n",
    "                         query_info: Dict, context: str = \"\") -> str:\n",
    "        \"\"\"Generate a natural language response from query results using Gemini\"\"\"\n",
    "        \n",
    "        if not results:\n",
    "            return \"I couldn't find any data matching your query. Please try rephrasing your question.\"\n",
    "        \n",
    "        # Prepare results summary\n",
    "        results_summary = self.summarize_results(results, query_info)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Generate a natural, conversational response based on the following information:\n",
    "        \n",
    "        User Query: {query}\n",
    "        Query Type: {query_info.get('operation', 'unknown')}\n",
    "        Collection: {query_info.get('collection', 'unknown')}\n",
    "        \n",
    "        Results Summary: {results_summary}\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Guidelines:\n",
    "        - Be conversational and helpful\n",
    "        - Highlight key insights from the data\n",
    "        - If showing specific records, mention the most interesting ones\n",
    "        - Keep response concise but informative\n",
    "        - If this is a follow-up question, reference previous context appropriately\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.config.MODEL_NAME,\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    max_output_tokens=self.config.MAX_OUTPUT_TOKENS,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            return response.text.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error generating response: {e}\")\n",
    "            return f\"I found {len(results)} results for your query about {query_info.get('collection', 'the database')}.\"\n",
    "    \n",
    "    def summarize_results(self, results: List[Dict], query_info: Dict) -> str:\n",
    "        \"\"\"Create a summary of query results\"\"\"\n",
    "        if not results:\n",
    "            return \"No results found.\"\n",
    "        \n",
    "        summary = f\"Found {len(results)} result(s). \"\n",
    "        \n",
    "        if query_info.get('operation') == 'count':\n",
    "            if 'count' in results[0]:\n",
    "                summary += f\"Total count: {results[0]['count']}\"\n",
    "        elif len(results) <= 5:\n",
    "            summary += \"Sample data: \" + str(results[:3])\n",
    "        else:\n",
    "            summary += f\"First few results: {str(results[:2])}\"\n",
    "            \n",
    "        return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76b7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN CONVERSATIONAL AGENT WITH GEMINI CHAT SESSION\n",
    "# =============================================================================\n",
    "\n",
    "class ConversationalDatabaseAgent:\n",
    "    \"\"\"Main agent that orchestrates all components using Google Gemini\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"ğŸš€ Initializing Conversational Database Agent with Google Gemini 2.0 Flash...\")\n",
    "        \n",
    "        self.config = Config()\n",
    "        self.db_handler = DatabaseHandler(self.config)\n",
    "        self.nlp_processor = NLPProcessor(self.config)\n",
    "        self.memory = ConversationMemory()\n",
    "        self.response_generator = ResponseGenerator(self.config)\n",
    "        \n",
    "        # Initialize Gemini chat session for context continuity\n",
    "        self.gemini_client = genai.Client(api_key=self.config.GEMINI_API_KEY)\n",
    "        self.chat_session = None\n",
    "        self.initialize_chat_session()\n",
    "        \n",
    "        print(\"âœ… Agent initialized successfully with Google Gemini 2.0 Flash!\")\n",
    "        print(f\"ğŸ“Š Connected to database: {self.config.DATABASE_NAME}\")\n",
    "        print(f\"ğŸ“š Available collections: {', '.join(self.config.COLLECTIONS)}\")\n",
    "        print(f\"ğŸ¤– Using model: {self.config.MODEL_NAME}\")\n",
    "    \n",
    "    def initialize_chat_session(self):\n",
    "        \"\"\"Initialize a new Gemini chat session\"\"\"\n",
    "        try:\n",
    "            self.chat_session = self.gemini_client.chats.create(\n",
    "                model=self.config.MODEL_NAME,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=self.config.TEMPERATURE,\n",
    "                    max_output_tokens=self.config.MAX_OUTPUT_TOKENS\n",
    "                )\n",
    "            )\n",
    "            print(\"ğŸ’¬ Gemini chat session initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error initializing chat session: {e}\")\n",
    "            self.chat_session = None\n",
    "    \n",
    "    def process_query(self, user_query: str) -> str:\n",
    "        \"\"\"Process a user query and return response\"\"\"\n",
    "        try:\n",
    "            print(f\"\\nğŸ” Processing query: {user_query}\")\n",
    "            \n",
    "            # Check if it's a follow-up query\n",
    "            is_follow_up = self.memory.is_follow_up_query(user_query)\n",
    "            context = self.memory.get_context_for_query(user_query) if is_follow_up else \"\"\n",
    "            \n",
    "            # Classify and translate query\n",
    "            query_type = self.nlp_processor.classify_query_type(user_query)\n",
    "            # collection, mongo_query, operation = self.nlp_processor.translate_to_mongodb(\n",
    "            #     user_query, self.db_handler.schema_cache, query_type\n",
    "            # )\n",
    "            context = self.memory.get_context_for_query(user_query)\n",
    "            collection, mongo_query, operation = self.nlp_processor.translate_to_mongodb(\n",
    "                user_query, self.db_handler.schema_cache, query_type, context\n",
    "            )\n",
    "            \n",
    "            print(f\"ğŸ“ Query Type: {query_type}\")\n",
    "            print(f\"ğŸ—ƒï¸ Target Collection: {collection}\")\n",
    "            print(f\"âš™ï¸ Operation: {operation}\")\n",
    "            print(f\"ğŸ”§ MongoDB Query: {mongo_query}\")\n",
    "            \n",
    "            # Execute query\n",
    "            results = self.db_handler.execute_query(collection, mongo_query, operation)\n",
    "            \n",
    "            # Prepare query info\n",
    "            query_info = {\n",
    "                'collection': collection,\n",
    "                'query': mongo_query,\n",
    "                'operation': operation,\n",
    "                'query_type': query_type\n",
    "            }\n",
    "            \n",
    "            # Generate response using Gemini chat session for context continuity\n",
    "            if self.chat_session:\n",
    "                enhanced_query = f\"\"\"\n",
    "                Database Query Result Analysis:\n",
    "                User Question: {user_query}\n",
    "                Database Collection: {collection}\n",
    "                Query Results: {str(results)[:1000] if results else 'No results found'}\n",
    "                \n",
    "                {context}\n",
    "                \n",
    "                Please provide a helpful, conversational response about these database results.\n",
    "                \"\"\"\n",
    "                \n",
    "                try:\n",
    "                    chat_response = self.chat_session.send_message(enhanced_query)\n",
    "                    response = chat_response.text\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Chat session error, using fallback: {e}\")\n",
    "                    response = self.response_generator.generate_response(\n",
    "                        user_query, results, query_info, context\n",
    "                    )\n",
    "            else:\n",
    "                response = self.response_generator.generate_response(\n",
    "                    user_query, results, query_info, context\n",
    "                )\n",
    "            \n",
    "            # Store interaction in memory\n",
    "            self.memory.add_interaction(user_query, response, query_info)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_message = f\"I encountered an error while processing your query: {str(e)}\"\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            return error_message\n",
    "    \n",
    "    def get_database_info(self) -> str:\n",
    "        \"\"\"Get information about the connected database\"\"\"\n",
    "        info = f\"Connected to MongoDB database: {self.config.DATABASE_NAME}\\n\"\n",
    "        info += f\"Using Google Gemini 2.0 Flash (Free Tier)\\n\\n\"\n",
    "        \n",
    "        for collection_name in self.config.COLLECTIONS:\n",
    "            stats = self.db_handler.get_collection_stats(collection_name)\n",
    "            info += f\"ğŸ“Š {collection_name.upper()}:\\n\"\n",
    "            info += f\"   - Total documents: {stats.get('total_documents', 'Unknown')}\\n\"\n",
    "            \n",
    "            if collection_name in self.db_handler.schema_cache:\n",
    "                schema = self.db_handler.schema_cache[collection_name]\n",
    "                info += f\"   - Fields: {', '.join(schema['fields'].keys())}\\n\"\n",
    "            \n",
    "            info += \"\\n\"\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def get_conversation_history(self) -> str:\n",
    "        \"\"\"Get conversation history summary\"\"\"\n",
    "        return self.memory.get_conversation_summary()\n",
    "    \n",
    "    def reset_chat_session(self):\n",
    "        \"\"\"Reset the Gemini chat session for a fresh start\"\"\"\n",
    "        self.initialize_chat_session()\n",
    "        self.memory = ConversationMemory()\n",
    "        print(\"ğŸ”„ Chat session and memory reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1feb77fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Initializing Conversational Database Agent with Google Gemini 2.0 Flash...\n",
      "âœ… Successfully connected to MongoDB Atlas\n",
      "ğŸ” Discovering database schema...\n",
      "ğŸ“‹ Schema discovered for accounts\n",
      "ğŸ“‹ Schema discovered for customers\n",
      "ğŸ“‹ Schema discovered for transactions\n",
      "ğŸ’¬ Gemini chat session initialized\n",
      "âœ… Agent initialized successfully with Google Gemini 2.0 Flash!\n",
      "ğŸ“Š Connected to database: sample_analytics\n",
      "ğŸ“š Available collections: accounts, customers, transactions\n",
      "ğŸ¤– Using model: gemini-2.0-flash\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "class GradioChatInterface:\n",
    "    def __init__(self):\n",
    "        self.agent = ConversationalDatabaseAgent()\n",
    "\n",
    "    def chat(self, message, history):\n",
    "        response = self.agent.process_query(message)\n",
    "        history = history or []\n",
    "        history.append((message, response))\n",
    "        return \"\", history\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.agent.reset_chat_session()  # This resets both chat session and conversation memory\n",
    "        return \"\", []  # Clears the input box and chat history\n",
    "\n",
    "    def launch(self):\n",
    "        with gr.Blocks() as demo:\n",
    "            gr.Markdown(\"## ğŸ’¬ Conversational Database Agent\")\n",
    "            chat = gr.Chatbot()\n",
    "            msg = gr.Textbox(placeholder=\"Ask a question about the database...\", show_label=False)\n",
    "            msg.submit(self.chat, [msg, chat], [msg, chat])\n",
    "            clear_btn = gr.Button(\"Clear Chat Memory\")\n",
    "            clear_btn.click(self.clear_memory, outputs=[msg, chat])\n",
    "        demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    GradioChatInterface().launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f003a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
